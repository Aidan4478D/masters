@misc{khattakCompSLAMComplementaryHierarchical2025,
  title = {{{CompSLAM}}: {{Complementary Hierarchical Multi-Modal Localization}} and {{Mapping}} for {{Robot Autonomy}} in {{Underground Environments}}},
  shorttitle = {{{CompSLAM}}},
  author = {Khattak, Shehryar and Homberger, Timon and Bernreiter, Lukas and Nubert, Julian and Andersson, Olov and Siegwart, Roland and Alexis, Kostas and Hutter, Marco},
  year = {2025},
  month = may,
  number = {arXiv:2505.06483},
  eprint = {2505.06483},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.06483},
  urldate = {2025-09-23},
  abstract = {Robot autonomy in unknown, GPS-denied, and complex underground environments requires real-time, robust, and accurate onboard pose estimation and mapping for reliable operations. This becomes particularly challenging in perception-degraded subterranean conditions under harsh environmental factors, including darkness, dust, and geometrically self-similar structures. This paper details CompSLAM, a highly resilient and hierarchical multi-modal localization and mapping framework designed to address these challenges. Its flexible architecture achieves resilience through redundancy by leveraging the complementary nature of pose estimates derived from diverse sensor modalities. Developed during the DARPA Subterranean Challenge, CompSLAM was successfully deployed on all aerial, legged, and wheeled robots of Team Cerberus during their competition-winning final run. Furthermore, it has proven to be a reliable odometry and mapping solution in various subsequent projects, with extensions enabling multi-robot map sharing for marsupial robotic deployments and collaborative mapping. This paper also introduces a comprehensive dataset acquired by a manually teleoperated quadrupedal robot, covering a significant portion of the DARPA Subterranean Challenge finals course. This dataset evaluates CompSLAM's robustness to sensor degradations as the robot traverses 740 meters in an environment characterized by highly variable geometries and demanding lighting conditions. The CompSLAM code and the DARPA SubT Finals dataset are made publicly available for the benefit of the robotics community},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/sophiaklymchuk/Zotero/storage/VZNEAY45/Khattak et al. - 2025 - CompSLAM Complementary Hierarchical Multi-Modal Localization and Mapping for Robot Autonomy in Unde.pdf;/Users/sophiaklymchuk/Zotero/storage/ZLZINYAE/2505.html}
}

@misc{tranzattoTeamCERBERUSWins2022,
  title = {Team {{CERBERUS Wins}} the {{DARPA Subterranean Challenge}}: {{Technical Overview}} and {{Lessons Learned}}},
  shorttitle = {Team {{CERBERUS Wins}} the {{DARPA Subterranean Challenge}}},
  author = {Tranzatto, Marco and Dharmadhikari, Mihir and Bernreiter, Lukas and Camurri, Marco and Khattak, Shehryar and Mascarich, Frank and Pfreundschuh, Patrick and Wisth, David and Zimmermann, Samuel and Kulkarni, Mihir and Reijgwart, Victor and Casseau, Benoit and Homberger, Timon and Petris, Paolo De and Ott, Lionel and Tubby, Wayne and Waibel, Gabriel and Nguyen, Huan and Cadena, Cesar and Buchanan, Russell and Wellhausen, Lorenz and Khedekar, Nikhil and Andersson, Olov and Zhang, Lintong and Miki, Takahiro and Dang, Tung and Mattamala, Matias and Montenegro, Markus and Meyer, Konrad and Wu, Xiangyu and Briod, Adrien and Mueller, Mark and Fallon, Maurice and Siegwart, Roland and Hutter, Marco and Alexis, Kostas},
  year = {2022},
  month = jul,
  number = {arXiv:2207.04914},
  eprint = {2207.04914},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2207.04914},
  urldate = {2025-09-23},
  abstract = {This article presents the CERBERUS robotic system-of-systems, which won the DARPA Subterranean Challenge Final Event in 2021. The Subterranean Challenge was organized by DARPA with the vision to facilitate the novel technologies necessary to reliably explore diverse underground environments despite the grueling challenges they present for robotic autonomy. Due to their geometric complexity, degraded perceptual conditions combined with lack of GPS support, austere navigation conditions, and denied communications, subterranean settings render autonomous operations particularly demanding. In response to this challenge, we developed the CERBERUS system which exploits the synergy of legged and flying robots, coupled with robust control especially for overcoming perilous terrain, multi-modal and multi-robot perception for localization and mapping in conditions of sensor degradation, and resilient autonomy through unified exploration path planning and local motion planning that reflects robot-specific limitations. Based on its ability to explore diverse underground environments and its high-level command and control by a single human supervisor, CERBERUS demonstrated efficient exploration, reliable detection of objects of interest, and accurate mapping. In this article, we report results from both the preliminary runs and the final Prize Round of the DARPA Subterranean Challenge, and discuss highlights and challenges faced, alongside lessons learned for the benefit of the community.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/sophiaklymchuk/Zotero/storage/G5JJF6X9/Tranzatto et al. - 2022 - Team CERBERUS Wins the DARPA Subterranean Challenge Technical Overview and Lessons Learned.pdf;/Users/sophiaklymchuk/Zotero/storage/55EDU4A7/2207.html}
}

@misc{1910146PermitrequiredConfined,
  title = {1910.146 - {{Permit-required}} Confined Spaces {\textbar} {{Occupational Safety}} and {{Health Administration}}},
  urldate = {2025-09-30},
  howpublished = {https://www.osha.gov/laws-regs/regulations/standardnumber/1910/1910.146}
}

@book{AdvancedMineRescue2020,
  title = {Advanced {{Mine Rescue Training Coal Mines}}},
  year = {2020},
  series = {Instruction {{Guide Series}}},
  number = {7},
  publisher = {{U.S. Department of Labor Mine Safety and Health Administration National Mine Health and Safety Academy}},
  langid = {english},
  file = {/Users/sophiaklymchuk/Zotero/storage/2IQ5MSQW/Advanced Mine Rescue Training Coal Mines.pdf;/Users/sophiaklymchuk/Zotero/storage/89VLS2YS/Advanced Mine Rescue Training Coal Mines.pdf}
}

@article{allanLowCostExperimentalQuadcopter2025,
  title = {A {{Low-Cost Experimental Quadcopter Drone Design}} for {{Autonomous Search-and-Rescue Missions}} in {{GNSS-Denied Environments}}},
  author = {Allan, Shane and Barczyk, Martin},
  year = {2025},
  month = aug,
  journal = {Drones},
  volume = {9},
  number = {8},
  pages = {523},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2504-446X},
  doi = {10.3390/drones9080523},
  urldate = {2025-09-23},
  abstract = {Autonomous drones may be called on to perform search-and-rescue operations in environments without access to signals from the global navigation satellite system (GNSS), such as underground mines, subterranean caverns, or confined tunnels. While technology to perform such missions has been demonstrated at events such as DARPA's Subterranean (Sub-T) Challenge, the hardware deployed for these missions relies on heavy and expensive sensors, such as LiDAR, carried by costly mobile platforms, such as legged robots and heavy-lift multicopters, creating barriers for deployment and training with this technology for all but the wealthiest search-and-rescue organizations. To address this issue, we have developed a custom four-rotor aerial drone platform specifically built around low-cost low-weight sensors in order to minimize costs and maximize flight time for search-and-rescue operations in GNSS-denied environments. We document the various issues we encountered during the building and testing of the vehicle and how they were solved, for instance a novel redesign of the airframe to handle the aggressive yaw maneuvers commanded by the FUEL exploration framework running onboard the drone. The resulting system is successfully validated through a hardware autonomous flight experiment performed in an underground environment without access to GNSS signals. The contribution of the article is to share our experiences with other groups interested in low-cost search-and-rescue drones to help them advance their own programs.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {autonomous exploration,drone design,path planning,search-and-rescue},
  file = {/Users/sophiaklymchuk/Zotero/storage/8NUQH26N/Allan and Barczyk - 2025 - A Low-Cost Experimental Quadcopter Drone Design for Autonomous Search-and-Rescue Missions in GNSS-De.pdf}
}

@article{bogueDisasterReliefSearch2019,
  title = {Disaster Relief, and Search and Rescue Robots: The Way Forward},
  shorttitle = {Disaster Relief, and Search and Rescue Robots},
  author = {Bogue, Robert},
  year = {2019},
  journal = {The Industrial Robot},
  volume = {46},
  number = {2},
  pages = {181--187},
  publisher = {Emerald Group Publishing Limited},
  address = {Bedford, United Kingdom},
  issn = {0143991X},
  doi = {10.1108/IR-11-2018-0227},
  urldate = {2025-09-23},
  abstract = {Purpose This paper aims to provide an insight into the future for disaster relief (DR) and search and rescue (SAR) robots by considering research activities which seek to address real-world applications and by identifying key user requirements and development priorities. Following a short introduction, this first provides a brief overview of the use of robots in DR and SAR and gives examples of organisations promoting their use. This is followed by details of development programmes aimed at meeting users' requirements. Specific needs are identified and considered in detail and were derived from both the literature and through discussions with users. This paper concludes with a tabulated summary of key development priorities. This study shows that several collaborative research programmes aim to address real DR and SAR applications, with robots being tested in simulated disaster scenarios. A number of key user requirements and development priorities are identified for aerial, ground and marine robots. By identifying a number of specific requirements, this paper will assist in focussing research and development activities towards real users' needs.},
  copyright = {{\copyright} Emerald Publishing Limited 2019},
  langid = {english},
  keywords = {Communication,Disaster relief,Disasters,Drones,Earthquakes,Evacuations & rescues,Floods,Humanitarianism,Infrastructure,Mass casualty incidents,Medical supplies,Mining accidents & safety,Nuclear accidents & safety,Nuclear power plants,Priorities,Research & development--R&D,Robotics,Robots,Search and rescue missions,Seismic engineering,Storm damage,Teams,Tsunamis,User requirements,Vehicles},
  file = {/Users/sophiaklymchuk/Zotero/storage/QKPV9IIK/Bogue - 2019 - Disaster relief, and search and rescue robots the way forward.pdf}
}

@article{chenRobotsHumansDisaster2023,
  title = {Robots or Humans for Disaster Response? {{Impact}} on Consumer Prosociality and Possible Explanations},
  shorttitle = {Robots or Humans for Disaster Response?},
  author = {Chen, Fangyuan and Huang, Szu-chi},
  year = {2023},
  journal = {Journal of Consumer Psychology},
  volume = {33},
  number = {2},
  pages = {432--440},
  issn = {1532-7663},
  doi = {10.1002/jcpy.1338},
  urldate = {2025-09-23},
  abstract = {Hurricanes, wildfires, pandemics, and other disasters have taken millions of lives in the past few years and caused substantial economic losses. To tackle these extraordinary circumstances, governments, organizations, and companies seek assistance from both humans and high-technology machines such as robots. This research report documents how highlighting robots' (vs. humans') helping behaviors in disaster response can affect consumers' prosociality, explores driving mechanisms, and tests solutions. Study 1 found that consumers donated fewer items of clothing after watching news highlighting robots' (vs. humans') assistance in a mudslide disaster. Featuring the COVID-19 pandemic, Study 2 further showed that this decrease in prosociality occurred because reading about robots' assistance felt less encouraging/inspiring to consumers. Studies 3A-3C (and a supplemental study) explored multiple mechanisms and identified a key driver for the backfire effect---a lower perception of courage in disaster response robots. Accordingly, Study 4 tested three theory-driven solutions to raise the perceived courage in robots to increase consumer prosociality.},
  langid = {english},
  keywords = {disaster response,donation,pandemic,prosociality,robots},
  file = {/Users/sophiaklymchuk/Zotero/storage/FBNHDWLN/Chen and Huang - 2023 - Robots or humans for disaster response Impact on consumer prosociality and possible explanations.pdf;/Users/sophiaklymchuk/Zotero/storage/GMX6CJI6/jcpy.html;/Users/sophiaklymchuk/Zotero/storage/TEUK7HTT/jcpy.html}
}

@article{chungRoboticDepthsAnalysis2023,
  title = {Into the {{Robotic Depths}}: {{Analysis}} and {{Insights}} from the {{DARPA Subterranean Challenge}}},
  shorttitle = {Into the {{Robotic Depths}}},
  author = {Chung, Timothy H. and Orekhov, Viktor and Maio, Angela},
  year = {2023},
  month = may,
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {6},
  number = {Volume 6, 2023},
  pages = {477--502},
  publisher = {Annual Reviews},
  issn = {2573-5144},
  doi = {10.1146/annurev-control-062722-100728},
  urldate = {2025-09-29},
  abstract = {The Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge represented a multiyear (2018--2021), competition-based initiative to inspire and shape the future of field robotics, specifically in advancing integrated technologies for operating in complex underground environments. Bringing together robotics researchers and innovators from around the world to compete in physical and simulated contests, it spotlighted significant opportunities to incentivize and extract high-value technical results and insights to inform future advances. This article captures and quantifies these results, extracts relevant insights, and offers lessons learned and recommendations for further work.},
  langid = {english},
  file = {/Users/sophiaklymchuk/Zotero/storage/JDGWANC8/Chung et al. - 2023 - Into the Robotic Depths Analysis and Insights from the DARPA Subterranean Challenge.pdf;/Users/sophiaklymchuk/Zotero/storage/ENBRX73I/annurev-control-062722-100728.html;/Users/sophiaklymchuk/Zotero/storage/VTZ7J36N/annurev-control-062722-100728.html}
}

@misc{DARPAsSubterraneanChallenge,
  title = {Inside {{DARPA}}'s {{Subterranean Challenge}} - {{IEEE Spectrum}}},
  urldate = {2025-09-30},
  howpublished = {https://spectrum.ieee.org/darpa-subterranean-challenge-2657170650}
}

@misc{DARPASubterraneanChallenge2021,
  title = {{{DARPA Subterranean Challenge Competition Rules}}: {{Final Event}}},
  year = {2021},
  month = may,
  publisher = {Defense Advanced Research Projects Agency},
  file = {/Users/sophiaklymchuk/Zotero/storage/7QRQVECT/SubT_Challenge_Finals_Rules.pdf}
}

@inproceedings{decubberEUICARUSProjectDeveloping2013,
  title = {The {{EU-ICARUS}} Project: {{Developing}} Assistive Robotic Tools for Search and Rescue Operations},
  shorttitle = {The {{EU-ICARUS}} Project},
  booktitle = {2013 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {De Cubber, Geert and Doroftei, Daniela and Serrano, Daniel and Chintamani, Keshav and Sabino, Rui and Ourevitch, Stephane},
  year = {2013},
  month = oct,
  pages = {1--4},
  publisher = {IEEE},
  address = {Linkoping, Sweden},
  doi = {10.1109/SSRR.2013.6719323},
  urldate = {2025-09-30},
  isbn = {978-1-4799-0880-6 978-1-4799-0879-0},
  file = {/Users/sophiaklymchuk/Zotero/storage/R6RH5C8A/De Cubber et al. - 2013 - The EU-ICARUS project Developing assistive robotic tools for search and rescue operations.pdf}
}

@article{dorofteiDesigningSearchRescue2014,
  title = {Designing {{Search}} and {{Rescue Robots}} towards {{Realistic User Requirements}}},
  author = {Doroftei, Daniela and Matos, Anibal and De Cubber, Geert},
  year = {2014},
  month = oct,
  journal = {Applied Mechanics and Materials},
  volume = {658},
  pages = {612--617},
  issn = {1662-7482},
  doi = {10.4028/www.scientific.net/AMM.658.612},
  urldate = {2025-09-30},
  abstract = {In the event of a large crisis (think about typhoon Haiyan or the Tohoku earthquake and tsunami in Japan), a primordial task of the rescue services is the search for human survivors on the incident site. This is a complex and dangerous task, which often leads to loss of lives among the human crisis managers themselves. The introduction of unmanned search and rescue devices can offer a valuable tool to save human lives and to speed up the search and rescue process. In this context, the EU-FP7-ICARUS project [1] concentrates on the development of unmanned search and rescue technologies for detecting, locating and rescuing humans.A main factor which explains why there is so little robotic technology applied on the terrain in real-life search and rescue operations, is that the complex nature and difficult operating conditions of search and rescue operations pose heavy constraints on the mechanical design of the unmanned platforms. In this paper, we discuss the different user requirements which have an impact of the design of the mechanical systems (air, ground and marine robots). We show how these user requirements are obtained, how they are validated, how they lead to design specifications for operational prototypes which are tested in realistic operational conditions and we show how the final mechanical design specifications are derived from these different steps. An important aspect of all these design steps which is emphasized in this paper is to always keep the end-users (in this case the search and rescue workers) in the loop in order to come to realistic requirements and mechanical design specifications, ensuring the practical deployability [2] of the developed platforms.},
  copyright = {https://www.scientific.net/PolicyAndEthics/PublishingPolicies},
  file = {/Users/sophiaklymchuk/Zotero/storage/J72ZSV3F/Doroftei et al. - 2014 - Designing Search and Rescue Robots towards Realistic User Requirements.pdf}
}

@misc{Elios3Digitizing,
  title = {Elios 3 - {{Digitizing}} the Inaccessible},
  urldate = {2025-09-30},
  abstract = {Quickly turn asset data into digital insights, with Elios 3 - the first mapping and inspection indoor drone, offering an unmatched combination of intelligence, versatility and stability.},
  howpublished = {https://www.flyability.com/elios-3},
  langid = {english}
}

@misc{ELIOS3Technical,
  title = {{{ELIOS}} 3 {{Technical Specifications}}},
  publisher = {Flyability},
  urldate = {2025-09-30},
  file = {/Users/sophiaklymchuk/Zotero/storage/4T4P9MXD/20220519_E3_Tech_Spec_web_version.pdf}
}

@inproceedings{ganesanSmallDisasterRelief2011,
  title = {Small Disaster Relief Robots with Swarm Intelligence Routing},
  booktitle = {Proceedings of the 1st {{International Conference}} on {{Wireless Technologies}} for {{Humanitarian Relief}}},
  author = {Ganesan, Subramanium and Shakya, Manish and Aqueel, Aqueel F. and Nambiar, Lakshmi M.},
  year = {2011},
  month = dec,
  pages = {123--127},
  publisher = {ACM},
  address = {Amritapuri Kollam, Kerala India},
  doi = {10.1145/2185216.2185257},
  urldate = {2025-09-23},
  isbn = {978-1-4503-1011-6},
  langid = {english},
  file = {/Users/sophiaklymchuk/Zotero/storage/GUNPESAR/Ganesan et al. - 2011 - Small disaster relief robots with swarm intelligence routing.pdf}
}

@misc{INSARAGGUIDELINES2020,
  title = {{{INSARAG GUIDELINES}} 2020 -- {{INSARAG}}},
  urldate = {2025-09-30},
  langid = {american},
  file = {/Users/sophiaklymchuk/Zotero/storage/7GK3I6CY/INSARAG20Guidelines20Vol20II2C20Man20B.pdf}
}

@article{kingDronesDisasterZones2025,
  title = {Drones in {{Disaster Zones}}: {{How Advanced 3D Mapping Technology Can Help First Responders Save Lives}}},
  shorttitle = {Drones in {{Disaster Zones}}},
  author = {King, Megan},
  year = {2025},
  month = jan,
  journal = {NIST},
  publisher = {Megan King},
  urldate = {2025-09-30},
  abstract = {NIST is working to help emergency workers have more information in a crisis by encouraging the development of advanced drones at an affordable price},
  langid = {english},
  annotation = {Last Modified: 2025-03-18T08:26-04:00}
}

@incollection{murphyDisasterRobotics2016,
  title = {Disaster Robotics},
  booktitle = {Springer Handbook of Robotics},
  author = {Murphy, Robin R. and Tadokoro, Satoshi and Kleiner, Alexander},
  editor = {Siciliano, Bruno and Khatib, Oussama},
  year = {2016},
  pages = {1577--1604},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-32552-1_60},
  abstract = {Rescue robots have been used in at least 28 disasters in six countries since the first deployment to the 9/11 World Trade Center collapse. All types of robots have been used (land, sea, and aerial) and for all phases of a disaster (prevention, response, and recovery). This chapter will cover the basic characteristics of disasters and their impact on robotic design, and describe the robots actually used in disasters to date, with a special focus on Fukushima Daiichi, which is providing a rich proving ground for robotics. The chapter covers promising robot designs (e.\,g., snakes, legged locomotion) and concepts (e.\,g., robot teams or swarms, sensor networks), as well as progress and open issues in autonomy. The methods of evaluation in benchmarks for rescue robotics are discussed and the chapter concludes with a discussion of the fundamental problems and open issues facing rescue robotics, and their evolution from an interesting idea to widespread adoption.},
  isbn = {978-3-319-32552-1},
  file = {/Users/sophiaklymchuk/Zotero/storage/6QSGZTU3/Murphy et al. - 2016 - Disaster robotics.pdf}
}

@misc{NationalUrbanSearch2006,
  title = {National {{Urban Search}} \& {{Rescue}} ({{US}}\&{{R}}) {{Response System}}: {{Rescue Field Operations Guide}}},
  year = {2006},
  month = sep,
  publisher = {Federal Emergency Management Agency},
  urldate = {2025-09-30},
  lccn = {US\&R-23-FG},
  file = {/Users/sophiaklymchuk/Zotero/storage/L77LQ7MS/Microsoft Word - ROG Sec-0-01.doc.pdf}
}

@article{petrlikUAVsSurfaceCooperative2025,
  title = {{{UAVs Beneath}} the {{Surface}}: {{Cooperative Autonomy}} for {{Subterranean Search}} and {{Rescue}} in {{DARPA SubT}}},
  shorttitle = {{{UAVs Beneath}} the {{Surface}}},
  author = {Petrlik, Matej and Petracek, Pavel and Kratky, Vit and Musil, Tomas and Stasinchuk, Yurii and Vrba, Matous and Baca, Tomas and Hert, Daniel and Pecka, Martin and Svoboda, Tomas and Saska, Martin},
  year = {2025},
  journal = {IEEE Transactions on Field Robotics},
  volume = {2},
  eprint = {2206.08185},
  primaryclass = {cs},
  pages = {643--689},
  issn = {2997-1101},
  doi = {10.55417/fr.2023001},
  urldate = {2025-09-23},
  abstract = {This paper presents a novel approach for autonomous cooperating UAVs in search and rescue operations in subterranean domains with complex topology. The proposed system was ranked second in the Virtual Track of the DARPA SubT Finals as part of the team CTU-CRAS-NORLAB. In contrast to the winning solution that was developed specifically for the Virtual Track, the proposed solution also proved to be a robust system for deployment onboard physical UAVs flying in the extremely harsh and confined environment of the real-world competition. The proposed approach enables fully autonomous and decentralized deployment of a UAV team with seamless simulation-to-world transfer, and proves its advantage over less mobile UGV teams in the flyable space of diverse environments. The main contributions of the paper are present in the mapping and navigation pipelines. The mapping approach employs novel map representations -- SphereMap for efficient risk-aware long-distance planning, FacetMap for surface coverage, and the compressed topological-volumetric LTVMap for allowing multi-robot cooperation under low-bandwidth communication. These representations are used in navigation together with novel methods for visibility-constrained informed search in a general 3D environment with no assumptions about the environment structure, while balancing deep exploration with sensor-coverage exploitation. The proposed solution also includes a visual-perception pipeline for on-board detection and localization of objects of interest in four RGB stream at 5 Hz each without a dedicated GPU. Apart from participation in the DARPA SubT, the performance of the UAV system is supported by extensive experimental verification in diverse environments with both qualitative and quantitative evaluation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Multiagent Systems,Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/sophiaklymchuk/Zotero/storage/WP4J9292/Petrlik et al. - 2025 - UAVs Beneath the Surface Cooperative Autonomy for Subterranean Search and Rescue in DARPA SubT.pdf;/Users/sophiaklymchuk/Zotero/storage/SS2WPH94/2206.html}
}

@article{reddyMineRescueRobot2015,
  title = {Mine {{Rescue Robot System}} -- {{A Review}}},
  author = {Reddy, A. Hemanth and Kalyan, Balla and Murthy, {\relax Ch}. S. N.},
  year = {2015},
  month = jan,
  journal = {Procedia Earth and Planetary Science},
  series = {Global {{Challenges}}, {{Policy Framework}} \& {{Sustainable Development}} for {{Mining}} of {{Mineral}} and {{Fossil Energy Resources}} ({{GCPF}}:2015--20)},
  volume = {11},
  pages = {457--462},
  issn = {1878-5220},
  doi = {10.1016/j.proeps.2015.06.045},
  urldate = {2025-09-23},
  abstract = {Underground mining is beset with numerous problems such as ground movement (fall of roof/sides), inundation, air blast, etc.; apart from gas explosions and dust explosions that are restricted to coal mines. Whatever may be the cause and type of accident or the extent of damage caused, it is a horrendous task for the rescue team to reach the trapped miners. The accident/irrespirable zone contains increased levels of harmful gases like carbon dioxide and carbon monoxide and explosive gases like methane apart from a deficiency of Oxygen. The entire gallery or roadway is filled with dust and smoke, or water in case of inundation, hindering the visibility of rescue personnel. Thus, it is not an ideal situation for the rescue team to perform the operations. The first few hours after the disaster are the critical moments that could be the difference between life and death of the trapped miners. Hence, the ideal solution in such cases would be to deploy a wireless robot equipped with various gas sensors and cameras to aid visibility even in extremely low light conditions. This paper reviews some notable examples from the past and highlights important requirements for rescue robots along with some limitations encountered in the design of such robots.},
  keywords = {Autonomous,Firedamp,Robot,Sensors,Wireless.},
  file = {/Users/sophiaklymchuk/Zotero/storage/D2ICK74W/Reddy et al. - 2015 - Mine Rescue Robot System â€“ A Review.pdf;/Users/sophiaklymchuk/Zotero/storage/8N2NSHSZ/S187852201500096X.html}
}

@misc{SafetyFirstFlying,
  title = {Safety {{First}}: {{Flying}} the {{Elios}} 3 {{Drone Inside}} a {{Burnt Building}}},
  shorttitle = {Safety {{First}}},
  urldate = {2025-09-30},
  abstract = {The Elios 3 is designed to reach dangerous environments so people don't have to. Check out how it was used to inspect a burnt building to assess the safest way to begin reconstruction.},
  howpublished = {https://www.flyability.com/casestudies/drone-building-damage-assessment},
  langid = {english}
}

@article{surojayaFullyAutonomousUAV2024,
  title = {Towards {{Fully Autonomous UAV}}: {{Damaged Building-Opening Detection}} for {{Outdoor-Indoor Transition}} in {{Urban Search}} and {{Rescue}}},
  shorttitle = {Towards {{Fully Autonomous UAV}}},
  author = {Surojaya, Ali and Zhang, Ning and Bergado, John Ray and Nex, Francesco},
  year = {2024},
  month = jan,
  journal = {Electronics},
  volume = {13},
  number = {3},
  pages = {558},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics13030558},
  urldate = {2025-09-23},
  abstract = {Autonomous unmanned aerial vehicle (UAV) technology is a promising technology for minimizing human involvement in dangerous activities like urban search and rescue missions (USAR), both in indoor and outdoor. Automated navigation from outdoor to indoor environments is not trivial, as it encompasses the ability of a UAV to automatically map and locate the openings in a damaged building. This study focuses on developing a deep learning model for the detection of damaged building openings in real time. A novel damaged building-opening dataset containing images and mask annotations, as well as a comparison between single and multi-task learning-based detectors are given. The deep learning-based detector used in this study is based on YOLOv5. First, this study compared the different versions of YOLOv5 (i.e., small, medium, and large) capacity to perform damaged building-opening detections. Second, a multitask learning YOLOv5 was trained on the same dataset and compared with the single-task detector. The multitask learning (MTL) was developed based on the YOLOv5 object detection architecture, adding a segmentation branch jointly with the detection head. This study found that the MTL-based YOLOv5 can improve detection performance by combining detection and segmentation losses. The YOLOv5s-MTL trained on the damaged building-opening dataset obtained 0.648 mAP, an increase of 0.167 from the single-task-based network, while its inference speed was 73 frames per second on the tested platform.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {damaged building opening,image segmentation,multitask learning,object detection,YOLOv5},
  file = {/Users/sophiaklymchuk/Zotero/storage/JU2YQKWB/Surojaya et al. - 2024 - Towards Fully Autonomous UAV Damaged Building-Opening Detection for Outdoor-Indoor Transition in Ur.pdf}
}

@misc{SurveyingSewers4X,
  title = {Surveying {{Sewers 4X}} Faster with the {{Elios}} 3},
  urldate = {2025-09-30},
  abstract = {A surveying company used the Elios 3 to safely map an underground sewer with 0 confined space entry and accurate to within 20 mm.},
  howpublished = {https://www.flyability.com/casestudies/drone-sewer-survey},
  langid = {english}
}
